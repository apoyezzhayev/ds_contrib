{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gscloud\n",
    "\n",
    "> Google cloud browser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp tools.io.gscloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | export\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import tempfile\n",
    "from datetime import datetime\n",
    "from itertools import repeat\n",
    "from pathlib import Path\n",
    "from typing import Iterable, Literal\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from google import resumable_media\n",
    "from google.cloud import storage\n",
    "from google.cloud.storage import Blob\n",
    "from google.oauth2 import service_account\n",
    "from nbdev import show_doc\n",
    "from pydantic import PathNotADirectoryError\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from ds_contrib.core.paths import (\n",
    "    Directory,\n",
    "    PathLike,\n",
    "    list_paths,\n",
    "    prepare_paths_for_transfer,\n",
    ")\n",
    "from ds_contrib.core.utils import Iterifiable, listify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "# | hide\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GSBrowserContext\n",
    "\n",
    "GSBrowserContext - pathlike representation of bucket and prefix for `gs://` URIs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "URL = str\n",
    "URI = str\n",
    "\n",
    "\n",
    "class GSBrowserContextDTO:\n",
    "    def __init__(\n",
    "        self,\n",
    "        path: Path | str,\n",
    "        prev: GSBrowserContextDTO | None = None,\n",
    "        is_dir: bool | None = None,\n",
    "    ):\n",
    "        self._is_dir = str(path).endswith(\"/\") if is_dir is None else is_dir\n",
    "        self._path: Path = Path(path)\n",
    "        self._prev: GSBrowserContextDTO | None = prev\n",
    "\n",
    "    @property\n",
    "    def bucket(self) -> str:\n",
    "        return self._path.parts[0]\n",
    "\n",
    "    def set_prev(self, prev: GSBrowserContextDTO):\n",
    "        self._prev = prev\n",
    "\n",
    "    @property\n",
    "    def prefix(self) -> str | None:\n",
    "        if len(self._path.parts) == 1:\n",
    "            return None\n",
    "        else:\n",
    "            return \"/\".join(self._path.parts[1:]) + (\"/\" if self._is_dir else \"\")\n",
    "\n",
    "    @property\n",
    "    def path(self) -> str:\n",
    "        return str(self._path) + (\"/\" if self._is_dir else \"\")\n",
    "\n",
    "    def is_dir(self) -> bool:\n",
    "        return self._is_dir\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            f\"GSBrowserContext:\\n\"\n",
    "            f\"\\tbucket | {self.bucket}\\n\"\n",
    "            f\"\\tprefix | {self.prefix}\\n\"\n",
    "            f\"\\tis_dir | {self.is_dir()}\\n\"\n",
    "            f\"\\tback | {self._prev.path if self._prev else None}\\n\"\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def uri(self) -> URI:\n",
    "        return f\"gs://{self.path}\"\n",
    "\n",
    "    @property\n",
    "    def url(self) -> URL:\n",
    "        return f\"https://storage.cloud.google.com/{self.path}\"\n",
    "\n",
    "    @property\n",
    "    def public_url(self) -> URL:\n",
    "        return f\"https://storage.googleapis.com/{self.path}\"\n",
    "\n",
    "    @property\n",
    "    def parent(self) -> GSBrowserContextDTO | None:\n",
    "        if len(self._path.parts) == 1:\n",
    "            return GSBrowserContextDTO(self._path, is_dir=True)\n",
    "        else:\n",
    "            return GSBrowserContextDTO(self._path.parent, is_dir=True, prev=self)\n",
    "\n",
    "    def back(self) -> GSBrowserContextDTO | None:\n",
    "        return self._prev\n",
    "\n",
    "    @classmethod\n",
    "    def from_url(\n",
    "        cls,\n",
    "        url: URL,\n",
    "        is_dir: bool | None = None,\n",
    "        scheme: str = \"https\",\n",
    "        netloc: Iterifiable[str] = None,\n",
    "    ):\n",
    "        url_dto = urlparse(url, scheme=scheme)\n",
    "        if url_dto.scheme != scheme:\n",
    "            raise ValueError(f\"url must be a `{scheme}`, got `{url_dto.scheme}`\")\n",
    "        netloc = (\n",
    "            listify(netloc)\n",
    "            if netloc\n",
    "            else [\"storage.googleapis.com\", \"storage.cloud.google.com\"]\n",
    "        )\n",
    "        if url_dto.netloc not in netloc:\n",
    "            raise ValueError(f\"url must be a `{netloc}`, got {url_dto.netloc}\")\n",
    "        if len(url_dto.path) < 2:\n",
    "            raise ValueError(f\"url must have a prefix\")\n",
    "        return cls(url_dto.path[1:], is_dir=is_dir)\n",
    "\n",
    "    @classmethod\n",
    "    def from_uri(cls, uri: URI, is_dir: bool | None = None, scheme=\"gs\"):\n",
    "        uri_dto = urlparse(uri, scheme=scheme)\n",
    "        if uri_dto.scheme != scheme:\n",
    "            raise ValueError(f\"uri must be a `{scheme}`, got `{uri_dto.scheme}`\")\n",
    "        if len(uri_dto.netloc) == 0:\n",
    "            raise ValueError(f\"uri must have at least a bucket\")\n",
    "        return cls(\"/\".join((uri_dto.netloc, uri_dto.path)), is_dir=is_dir)\n",
    "\n",
    "\n",
    "GSBrowserContext = GSBrowserContextDTO | None | str | Path | URL | URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GSBrowserContext:\n",
       "\tbucket | roadly-dev-standard-videos\n",
       "\tprefix | 2022-11-18_22-03-05_C3E5F773-2BF/times.txt\n",
       "\tis_dir | False\n",
       "\tback | None"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GSBrowserContextDTO.from_url(\n",
    "    \"https://storage.cloud.google.com/roadly-dev-standard-videos/2022-11-18_22-03-05_C3E5F773-2BF/times.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GSBrowserContext:\n",
       "\tbucket | roadly-dev-standard-videos\n",
       "\tprefix | 2022-11-18_22-03-05_C3E5F773-2BF/times.txt\n",
       "\tis_dir | False\n",
       "\tback | None"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GSBrowserContextDTO.from_uri(\n",
    "    \"gs://roadly-dev-standard-videos/2022-11-18_22-03-05_C3E5F773-2BF/times.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GSBrowserContext:\n",
       "\tbucket | roadly-dev-standard-videos\n",
       "\tprefix | 2022-11-18_22-03-05_C3E5F773-2BF/times.txt\n",
       "\tis_dir | False\n",
       "\tback | None"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GSBrowserContextDTO.from_url(\n",
    "    \"https://storage.googleapis.com/roadly-dev-standard-videos/2022-11-18_22-03-05_C3E5F773-2BF/times.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GSBrowserContext:\n",
       "\tbucket | roadly-dev-standard-videos\n",
       "\tprefix | 2022-11-18_22-03-05_C3E5F773-2BF/times.txt\n",
       "\tis_dir | False\n",
       "\tback | None"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = GSBrowserContextDTO(\n",
    "    \"roadly-dev-standard-videos/2022-11-18_22-03-05_C3E5F773-2BF/times.txt\"\n",
    ")\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roadly-dev-standard-videos/2022-11-18_22-03-05_C3E5F773-2BF/times.txt\n",
      "gs://roadly-dev-standard-videos/2022-11-18_22-03-05_C3E5F773-2BF/times.txt\n",
      "https://storage.cloud.google.com/roadly-dev-standard-videos/2022-11-18_22-03-05_C3E5F773-2BF/times.txt\n",
      "https://storage.googleapis.com/roadly-dev-standard-videos/2022-11-18_22-03-05_C3E5F773-2BF/times.txt\n"
     ]
    }
   ],
   "source": [
    "print(c.path, c.uri, c.url, c.public_url, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSBrowserContext:\n",
      "\tbucket | roadly-dev-standard-videos\n",
      "\tprefix | 2022-11-18_22-03-05_C3E5F773-2BF/\n",
      "\tis_dir | True\n",
      "\tback | roadly-dev-standard-videos/2022-11-18_22-03-05_C3E5F773-2BF/times.txt\n",
      "\n",
      "roadly-dev-standard-videos/2022-11-18_22-03-05_C3E5F773-2BF/times.txt\n",
      "roadly-dev-standard-videos\n"
     ]
    }
   ],
   "source": [
    "print(c.parent, c.path, c.bucket, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def is_uri(path: str):\n",
    "    providers = (\"gs://\", \"s3://\")\n",
    "    return any(path.startswith(provider) for provider in providers)\n",
    "\n",
    "\n",
    "def is_url(path: str):\n",
    "    return path.startswith(\"http://\") or path.startswith(\"https://\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GSBrowser\n",
    "\n",
    "The main client for accessing data on google storage thorugh python API. May be used for listing, reading, writing and navigating data on google storage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "from ds_contrib.core.paths import shared_root\n",
    "\n",
    "\n",
    "class GSBrowser:\n",
    "    # TODO(H): add asynchronous and batch network I/O\n",
    "    def __init__(\n",
    "        self,\n",
    "        project: str,\n",
    "        credentials: PathLike,\n",
    "        default_context: GSBrowserContext = None,\n",
    "        downloads_dir: Directory | None = None,\n",
    "    ):\n",
    "        \"\"\"Google Storage Browser\n",
    "\n",
    "        Object for browsing Google Storage buckets and internal data, downloading/uploading files and folders\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        project : str\n",
    "            Google Cloud project name\n",
    "        credentials : PathLike\n",
    "            path to service account credentials file in json format\n",
    "        default_context : GSBrowserContextDTO | None, optional\n",
    "            starting root path (prefix) in GSBrowser, by default None\n",
    "        downloads_dir : PathLike, optional\n",
    "            default directory used for downloads, by default None\n",
    "            - if None, then temporary directory is created, remove it after usage with `cleanup` method\n",
    "            - if Path, then persistent directory is created, remove it manually if necessary, if Path does not exist, it will be created\n",
    "        \"\"\"\n",
    "        credentials = service_account.Credentials.from_service_account_file(credentials)\n",
    "        self.storage_client: storage.Client = storage.Client(\n",
    "            project=project, credentials=credentials\n",
    "        )\n",
    "        # self._context: GSBrowserContext = default(default_context, GSBrowserContext())\n",
    "        self._context: GSBrowserContextDTO | None = (\n",
    "            default_context  # TODO: add handling of all types of contexts\n",
    "        )\n",
    "        self._buckets = None\n",
    "        self._downloads_dir = (\n",
    "            downloads_dir if downloads_dir else Directory(Path.cwd(), temporary=True)\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def downloads_path(self) -> Path:\n",
    "        \"\"\"Lazy init of downloads_dir, if download dir is not specified in init, then temporary directory is created, remove it after usage with `cleanup` method\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Path\n",
    "            to local downloads directory\n",
    "        \"\"\"\n",
    "        return self._downloads_dir.path\n",
    "\n",
    "    @property\n",
    "    def downloads_dir(self) -> Directory:\n",
    "        return self._downloads_dir\n",
    "\n",
    "    def is_absolute(self, path: str):\n",
    "        if path.startswith(\"/\"):\n",
    "            raise ValueError(f\"path must start from bucket not a `/` got `{path}`\")\n",
    "        if self._buckets is None:  # lazy load\n",
    "            self._buckets = set({b.name for b in self.list_buckets()})\n",
    "        parts = Path(path).parts\n",
    "        if len(parts) == 0:\n",
    "            return False\n",
    "        else:\n",
    "            return parts[0] in self._buckets\n",
    "\n",
    "    def context(self) -> GSBrowserContextDTO | None:\n",
    "        \"\"\"Current context (cwd/pwd)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        GSBrowserContextDTO | None\n",
    "            current context\n",
    "        \"\"\"\n",
    "        return self._context\n",
    "\n",
    "    def list_buckets(self) -> list[storage.Bucket]:\n",
    "        \"\"\"List all buckets in the project\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list[storage.Bucket]\n",
    "        \"\"\"\n",
    "        buckets = list(self.storage_client.list_buckets())\n",
    "        return buckets\n",
    "\n",
    "    def cd(self, path: GSBrowserContext, check_existence=True):\n",
    "        \"\"\"Change current context to `path`,\n",
    "\n",
    "        analogous to `cd` in bash\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        path : GSBrowserContext\n",
    "            path to change context to\n",
    "        check_existence : bool, optional\n",
    "            if True, then check if the prefix exists in Google Storage, otherwise raise FileNotFoundError,\n",
    "        \"\"\"\n",
    "        self._set_context(path, check_existence)\n",
    "\n",
    "    def back(self):\n",
    "        \"\"\"Return to previous context\"\"\"\n",
    "        if self._context is not None:\n",
    "            self._context = self._context.back()\n",
    "\n",
    "    @property\n",
    "    def cwd(self) -> str:\n",
    "        \"\"\"Return current context path\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "        \"\"\"\n",
    "        return self._context.path\n",
    "\n",
    "    def _set_context(\n",
    "        self,\n",
    "        context: GSBrowserContext,\n",
    "        check_existence: bool = False,\n",
    "        is_dir: bool = True,\n",
    "    ):\n",
    "        new_context = self.parse_context(context, is_dir=is_dir)\n",
    "        if check_existence and not self.is_present(new_context):\n",
    "            raise FileNotFoundError(f\"No such file or directory: {context.path}\")\n",
    "        if self._context:\n",
    "            new_context.set_prev(self._context)\n",
    "        self._context = new_context\n",
    "\n",
    "    def parse_context(\n",
    "        self, context: GSBrowserContext, is_dir: bool = None\n",
    "    ) -> GSBrowserContextDTO:\n",
    "        \"\"\"Parse context from str, Path, URI, URL, GSBrowserContextDTO or None to GSBrowserContextDTO\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        context : GSBrowserContext\n",
    "            context to parse\n",
    "        is_dir : bool, optional\n",
    "            if True then consider context as directory, if False then consider context as file,\n",
    "            if None then infer from the prefix (if it ends with `/`), by default None\n",
    "            WARNING: if context is Path type, then leading `/` is ignored, so it is impossible to infer if it is a file\n",
    "                or directory and `is_dir` must be specified\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        GSBrowserContextDTO\n",
    "            parsed context\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        ValueError\n",
    "            if context is not GSBrowserContext, URI, URL or str\n",
    "        ValueError\n",
    "            if context is str and is not absolute path starting from bucket or current context is not set\n",
    "        \"\"\"\n",
    "        if context is None:\n",
    "            return self._context\n",
    "        if isinstance(context, GSBrowserContextDTO):\n",
    "            return context\n",
    "        elif isinstance(context, (str, PathLike)):\n",
    "            context = str(context)\n",
    "            is_dir = is_dir if is_dir is not None else context.endswith(\"/\")\n",
    "            if is_url(context):\n",
    "                return GSBrowserContextDTO.from_url(context, is_dir=is_dir)\n",
    "            elif is_uri(context):\n",
    "                return GSBrowserContextDTO.from_uri(context, is_dir=is_dir)\n",
    "            else:\n",
    "                if self.is_absolute(context):\n",
    "                    return GSBrowserContextDTO(context, is_dir=is_dir)\n",
    "                else:\n",
    "                    if self._context is None:\n",
    "                        raise ValueError(\n",
    "                            f\"Context must be absolute path starting from bucket or current context must be set, \"\n",
    "                            f\"got context: `{context}`\"\n",
    "                            f\"and current context: {self._context}\"\n",
    "                        )\n",
    "                    # use resolution in PosixPath format (e.g. emulate `/`)\n",
    "                    path = (Path(\"/\") / Path(self._context.path) / context).resolve()\n",
    "                    # Back to URI format\n",
    "                    path = str(path)[1:]\n",
    "                    return GSBrowserContextDTO(path, is_dir=is_dir)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"context must be GSBrowserContext, URI, URL or str got {type(context)}\"\n",
    "            )\n",
    "\n",
    "    def is_present(self, context: GSBrowserContext = None) -> bool:\n",
    "        \"\"\"Check if the prefix exists in Google Storage\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        context : GSBrowserContext, optional\n",
    "            context to check, if None, then current context is used, by default None\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        bool\n",
    "            True if the prefix exists in Google Storage, otherwise False\n",
    "        \"\"\"\n",
    "        blobs = self.list_blobs(context=context, as_dir=False, max_results=1)\n",
    "        is_files = next(blobs, None) is not None\n",
    "        is_subdirs = len(blobs.prefixes) > 0\n",
    "        return is_files or is_subdirs\n",
    "\n",
    "    # TODO: add max_results and pagination\n",
    "    def list_blobs(\n",
    "        self,\n",
    "        context: GSBrowserContext = None,\n",
    "        fields: str = None,\n",
    "        recursive: bool = False,\n",
    "        as_dir=None,\n",
    "        max_results: int = None,\n",
    "    ) -> Iterable[storage.Blob]:\n",
    "        \"\"\"List blobs in prefix directory\n",
    "\n",
    "        usually used internally or for very specific scenarios, use `list` method instead\n",
    "\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        context : GSBrowserContext, optional\n",
    "            prefix directory, root of the hierarchy, if None then current context is used, by default None\n",
    "        fields : str, optional\n",
    "            fields to return, see https://googleapis.dev/python/storage/latest/blobs.html#google.cloud.storage.blob.Blob, by default None\n",
    "        recursive : bool, optional\n",
    "            if True then list blobs recursively, by default False\n",
    "        as_dir : _type_, optional\n",
    "            if True then list blobs as directories, if False then list blobs as files, if None then infer from the prefix (if it ends with `/`), by default None\n",
    "        max_results : int, optional\n",
    "            maximum number of results to return, by default None\n",
    "        \"\"\"\n",
    "\n",
    "        # list subdirectories in prefix directory with depth = 1\n",
    "        context = self.parse_context(context, is_dir=as_dir)\n",
    "\n",
    "        delimiter = \"/\" if not recursive else None\n",
    "        blobs = self.storage_client.list_blobs(\n",
    "            context.bucket,\n",
    "            prefix=context.prefix,\n",
    "            delimiter=delimiter,\n",
    "            fields=fields,\n",
    "            max_results=max_results,\n",
    "        )\n",
    "        return blobs\n",
    "\n",
    "    def list(\n",
    "        self,\n",
    "        context: GSBrowserContext = None,\n",
    "        fields: str = None,\n",
    "        recursive: bool = False,\n",
    "        as_dir=None,\n",
    "        max_results: int = None,\n",
    "    ) -> dict[str, list[GSBrowserContextDTO]]:\n",
    "        \"\"\"List blobs as GSBrowserContextDTO files and folders in prefix directory\n",
    "\n",
    "        analogous to `ls` in bash\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        context : GSBrowserContext, optional\n",
    "            prefix directory, root of the hierarchy, if None then current context is used, by default None\n",
    "        fields : str, optional\n",
    "            fields to return, see https://googleapis.dev/python/storage/latest/blobs.html#google.cloud.storage.blob.Blob, by default None\n",
    "        recursive : bool, optional\n",
    "            if True then list blobs recursively, by default False, Warning: if True, then all blobs are listed and then filtered, may be slow\n",
    "        as_dir : _type_, optional\n",
    "            if True then consider prefix as directory, during listing subfolders and files will be returned,\n",
    "            if False then consider prefix as file, if it is a directory, then return only this directory GSBrowserContextDTO,\n",
    "            if None then infer from the prefix (if it ends with `/`), by default None\n",
    "        max_results : int, optional\n",
    "            maximum number of results to return, if None then all results are returned, by default None\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict[str, list[GSBrowserContextDTO]]\n",
    "            dictionary with keys `files` and `folders` with lists of GSBrowserContextDTO files and folders respectively\n",
    "        \"\"\"\n",
    "        context = self.parse_context(context, is_dir=as_dir)\n",
    "\n",
    "        # if check_existence:\n",
    "        #     if not self.is_present(context):\n",
    "        #         raise FileNotFoundError(f'No such file or directory: {context}')\n",
    "\n",
    "        blobs = self.list_blobs(\n",
    "            context=context,\n",
    "            fields=fields,\n",
    "            recursive=recursive,\n",
    "            as_dir=as_dir,\n",
    "            max_results=max_results,\n",
    "        )\n",
    "\n",
    "        # Important!: Consume blobs iterator.\n",
    "        # We assume that there is no direct files inside prefix, only subdirectories\n",
    "        # Use list to consume iterator\n",
    "        bucket = Path(blobs.bucket.name)\n",
    "        files = []\n",
    "        subdirectories = []\n",
    "\n",
    "        for blob in blobs:\n",
    "            if blob.name.endswith(\"/\"):\n",
    "                subdirectories.append(\n",
    "                    GSBrowserContextDTO(bucket / blob.name, is_dir=True)\n",
    "                )\n",
    "            else:\n",
    "                files.append(GSBrowserContextDTO(bucket / blob.name, is_dir=False))\n",
    "\n",
    "        # Prefixes are available then\n",
    "        subdirectories.extend(\n",
    "            [\n",
    "                GSBrowserContextDTO(bucket / sub_prefix, is_dir=True)\n",
    "                for sub_prefix in blobs.prefixes\n",
    "            ]\n",
    "        )\n",
    "        return {\"files\": files, \"folders\": subdirectories}\n",
    "\n",
    "    def _prepare_path(self, path: PathLike, blob: Blob) -> Path:\n",
    "        if path is None:\n",
    "            resolved_path: Path = self.downloads_path / blob.bucket.name / blob.name\n",
    "        else:\n",
    "            resolved_path = Path(path)\n",
    "        resolved_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        return resolved_path\n",
    "\n",
    "    def download_blob(\n",
    "        self,\n",
    "        blob: Blob,\n",
    "        destination_file_name: PathLike = None,\n",
    "        existing_handling: Literal[\"skip\", \"overwrite\", \"raise\"] = \"skip\",\n",
    "    ):\n",
    "        \"\"\"Download blob to local file\n",
    "\n",
    "        usually for internal usage, use `download_file` or `download_files` instead\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        blob : Blob\n",
    "            blob to download\n",
    "        destination_file_name : PathLike, optional\n",
    "            local file path to download blob to, if None, then use default path which corresponds to {download_dir}/{prefix}, by default None\n",
    "        existing_handling : Literal[&quot;skip&quot;, &quot;overwrite&quot;, &quot;raise&quot;], optional\n",
    "            how to handle existing files:\n",
    "                - &#39;skip&#39; - skip existing files\n",
    "                - &#39;overwrite&#39; - overwrite existing files\n",
    "                - &#39;raise&#39; - raise error if file already exists, by default &#39;skip&#39;\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        FileExistsError\n",
    "            if file already exists and exists_ok is False\n",
    "        \"\"\"\n",
    "        local_path = self._prepare_path(destination_file_name, blob)\n",
    "        if local_path.exists():\n",
    "            if existing_handling == \"skip\":\n",
    "                logger.warning(f\"File {local_path} already exists, skipping\")\n",
    "                return\n",
    "            elif existing_handling == \"overwrite\":\n",
    "                logger.info(f\"File {local_path} already exists, overwriting\")\n",
    "            elif existing_handling == \"raise\":\n",
    "                raise FileExistsError(f\"File {local_path} already exists\")\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Unknown existing_handling strategy: {existing_handling}\"\n",
    "                )\n",
    "\n",
    "        logger.info(f\"Downloading file from URI: `{blob.name}` to path: `{local_path}`\")\n",
    "        try:\n",
    "            with open(local_path, \"wb\") as file_obj:\n",
    "                self.storage_client.download_blob_to_file(blob, file_obj)\n",
    "        except resumable_media.DataCorruption:\n",
    "            # Delete the corrupt downloaded file.\n",
    "            os.remove(local_path)\n",
    "            raise\n",
    "\n",
    "    def download_file(\n",
    "        self,\n",
    "        context: GSBrowserContext,\n",
    "        local_path: PathLike = None,\n",
    "        existing_handling: Literal[\"skip\", \"overwrite\", \"raise\"] = \"skip\",\n",
    "    ):\n",
    "        \"\"\"Download a single file from GCP from context to local file\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        context : GSBrowserContextDTO | URI | URL | None, optional\n",
    "            context to download from, if None, then current context is used, by default None\n",
    "        local_path : PathLike, optional\n",
    "            local file path to download blob to, if None, then use default path which corresponds to {download_dir}/{prefix}, by default None\n",
    "        existing_handling : Literal[&quot;skip&quot;, &quot;overwrite&quot;, &quot;raise&quot;], optional\n",
    "            how to handle existing files:\n",
    "                - &#39;skip&#39; - skip existing files\n",
    "                - &#39;overwrite&#39; - overwrite existing files\n",
    "                - &#39;raise&#39; - raise error if file already exists, by default &#39;skip&#39;\n",
    "        \"\"\"\n",
    "        blobs = self.list_blobs(context=context, recursive=False, as_dir=False)\n",
    "        for blob in blobs:\n",
    "            self.download_blob(blob, local_path, existing_handling)\n",
    "\n",
    "    def get_local_paths_mapping(\n",
    "        self,\n",
    "        contexts: Iterifiable[GSBrowserContext],\n",
    "        local_root: PathLike = None,\n",
    "        remote_root: PathLike = None,\n",
    "    ) -> dict[GSBrowserContextDTO, Path]:\n",
    "        \"\"\"Maps remote paths (Contexts) to local paths\n",
    "\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        contexts : Iterifiable[GSBrowserContextDTO]\n",
    "            remote paths to map\n",
    "        local_root : PathLike, optional\n",
    "            local root path, if None, then use default path which corresponds to {download_dir}/{prefix}, by default None\n",
    "        remote_root : PathLike, optional\n",
    "            remote root path, if None, then shared root of all remote paths is used, by default None\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list[Path]\n",
    "            list of local paths\n",
    "        \"\"\"\n",
    "        local_root = (\n",
    "            Path(local_root).absolute().resolve() if local_root else self.downloads_path\n",
    "        )\n",
    "        contexts = [self.parse_context(c) for c in listify(contexts)]\n",
    "        absolute_remote_paths = list(map(lambda p: Path(\"/\" + p.path), contexts))\n",
    "        remote_root = (\n",
    "            remote_root\n",
    "            if remote_root\n",
    "            else shared_root(absolute_remote_paths, only_files=True)\n",
    "        )\n",
    "        local_paths_mapping = {\n",
    "            c: local_root / p.relative_to(remote_root)\n",
    "            for c, p in zip(contexts, absolute_remote_paths)\n",
    "        }\n",
    "        return local_paths_mapping\n",
    "\n",
    "    def download_files(\n",
    "        self,\n",
    "        contexts: Iterifiable[GSBrowserContext],\n",
    "        local_folder_path: PathLike = None,\n",
    "        remote_root: PathLike = None,\n",
    "        existing_handling: Literal[\"skip\", \"overwrite\", \"raise\"] = \"skip\",\n",
    "    ) -> None:\n",
    "        \"\"\"Analogue of `download_file` for multiple files use it for convenience\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        contexts : Iterifiable[GSBrowserContextDTO]\n",
    "            contexts to download from, may be a single context or a list of contexts\n",
    "        local_folder_path : PathLike, optional\n",
    "            local folder path to download blobs to, if None, then use default path which corresponds to {download_dir}/{prefix}, by default None\n",
    "        remote_root : PathLike, optional\n",
    "            remote root path, if None, then shared root of all remote paths is used, by default None\n",
    "        existing_handling : Literal[&quot;skip&quot;, &quot;overwrite&quot;, &quot;raise&quot;], optional\n",
    "            how to handle existing files:\n",
    "                - &#39;skip&#39; - skip existing files\n",
    "                - &#39;overwrite&#39; - overwrite existing files\n",
    "                - &#39;raise&#39; - raise error if file already exists, by default &#39;skip&#39;\n",
    "        \"\"\"\n",
    "        local_paths_mapping = self.get_local_paths_mapping(\n",
    "            contexts, local_folder_path, remote_root\n",
    "        )\n",
    "        for context, local_path in tqdm(\n",
    "            local_paths_mapping.items(),\n",
    "            total=len(local_paths_mapping),\n",
    "            desc=\"Downloading files from GCP\",\n",
    "        ):\n",
    "            self.download_file(context, local_path, existing_handling)\n",
    "\n",
    "    def upload_file(\n",
    "        self, local_path: PathLike, context: GSBrowserContext, exists_ok=False\n",
    "    ):\n",
    "        \"\"\"Upload a single file to GCP\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        local_path : PathLike\n",
    "            local file path to upload\n",
    "        context : GSBrowserContext\n",
    "            context to upload to (google cloud path)\n",
    "        exists_ok : bool, optional\n",
    "            if True, then skip uploading if file already exists, if False then raise FileExistsError, by default False\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        FileNotFoundError\n",
    "            If local_path does not exist\n",
    "        ValueError\n",
    "            If context is None\n",
    "        FileExistsError\n",
    "            If file already exists in google cloud and exists_ok is False\n",
    "        \"\"\"\n",
    "        local_path = Path(local_path)\n",
    "        if not local_path.exists():\n",
    "            raise FileNotFoundError(f\"No such file or directory: {local_path}\")\n",
    "        if context is None:\n",
    "            raise ValueError(\"Context must be specified\")\n",
    "        context = self.parse_context(context, is_dir=False)\n",
    "        blob = self.storage_client.bucket(context.bucket).blob(context.prefix)\n",
    "        if blob.exists() and not exists_ok:\n",
    "            raise FileExistsError(f\"File {context} already exists\")\n",
    "        logging.info(f\"Uploading file from path: `{local_path}` to URI: `{context}`\")\n",
    "        blob.upload_from_filename(local_path)\n",
    "\n",
    "    def upload_files(\n",
    "        self,\n",
    "        local_paths: Iterifiable[PathLike],\n",
    "        gcs_destination_root: GSBrowserContext,\n",
    "        duplicates_handling: Literal[\"overwrite\", \"skip\", \"error\"] | None = None,\n",
    "        recursive: bool = False,\n",
    "        local_shared_root: PathLike = None,\n",
    "        test_launch: bool = False,\n",
    "    ):\n",
    "        \"\"\"Upload multiple files to GCP\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        local_paths : Iterifiable[PathLike]\n",
    "            local paths to upload to GCP, may be iterable files and directories or a single file or directory\n",
    "        gcs_destination_root : GSBrowserContext\n",
    "            root directory context (GSBrowserContext), this directory will be used as a root prefix for all uploaded files\n",
    "        duplicates_handling : Literal[&quot;overwrite&quot;, &quot;skip&quot;, &quot;error&quot;] | None, optional\n",
    "            how to handle duplicates:\n",
    "                - if None, then no checks for file existence are performed,\n",
    "                - &#39;overwrite&#39; - overwrite existing files\n",
    "                - &#39;skip&#39; - skip existing files\n",
    "                - &#39;error&#39; - raise error if file already exists, by default None\n",
    "        recursive : bool, optional\n",
    "            if True, then upload folders recursively, otherwise only files of 1st level, by default False\n",
    "        local_shared_root : _type_, optional\n",
    "            local paths are treated as relative to this root,\n",
    "            if None shared root of all files and directories in `local_paths` will be extracted automatically,\n",
    "            try to avoid this due to unpredictability, by default None\n",
    "        test_launch : bool, optional\n",
    "            if True, then do not upload files, only print what will be uploaded, by default False\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        FileExistsError\n",
    "            If file already exists in google cloud and exists_ok is False\n",
    "        ValueError\n",
    "            If duplicates_handling is not one of &#39;overwrite&#39;, &#39;skip&#39;, &#39;error&#39;\n",
    "        \"\"\"\n",
    "        gcs_destination_root = self.parse_context(gcs_destination_root, is_dir=True)\n",
    "        local_paths = list(list_paths(local_paths, recursive=recursive))\n",
    "        contexts = prepare_paths_for_transfer(\n",
    "            local_paths,\n",
    "            recursive=False,\n",
    "            target_root=gcs_destination_root.path,\n",
    "            local_shared_root=local_shared_root,\n",
    "        )\n",
    "        contexts = [self.parse_context(context, is_dir=False) for context in contexts]\n",
    "        for local_path, context in tqdm(\n",
    "            zip(local_paths, contexts),\n",
    "            total=len(contexts),\n",
    "            desc=\"Uploading files to GCP\",\n",
    "            leave=False,\n",
    "        ):\n",
    "            if duplicates_handling and self.is_present(context):\n",
    "                if duplicates_handling == \"skip\":\n",
    "                    logging.info(f\"File {context} already exists, skipping\")\n",
    "                    continue\n",
    "                elif duplicates_handling == \"error\":\n",
    "                    raise FileExistsError(f\"File {context} already exists\")\n",
    "                elif duplicates_handling == \"overwrite\":\n",
    "                    logging.info(f\"File {context} already exists, overwriting\")\n",
    "                else:\n",
    "                    raise ValueError(\n",
    "                        f\"Unknown duplicates_handling strategy: {duplicates_handling}\"\n",
    "                    )\n",
    "            if test_launch:\n",
    "                print(f\"Uploading file from path: `{local_path}` to URI: `{context}`\")\n",
    "            else:\n",
    "                self.upload_file(\n",
    "                    local_path, context, exists_ok=(duplicates_handling == \"overwrite\")\n",
    "                )\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            f\"GSBrowser(project={self.storage_client.project}, context={self._context})\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'roadly-dev-standard-videos/2022-11-18_22-03-05_C3E5F773-2BF/gps.csv'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GSBrowserContextDTO.from_url(\n",
    "    \"https://storage.googleapis.com/roadly-dev-standard-videos/2022-11-18_22-03-05_C3E5F773-2BF/gps.csv\"\n",
    ").path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial configuration has finished:\n",
      "Project: {'project': 'roadly-project-dev', 'env': 'dev', 'coldline_name': 'standard'}\n"
     ]
    }
   ],
   "source": [
    "# | hide\n",
    "\n",
    "CONFIGS_DIR = Path(\"../../configs/storage/gscloud/\")\n",
    "ENV_DIR = Path(\"../../configs/env/local/\")\n",
    "\n",
    "with open(CONFIGS_DIR / \"projects_vars.json\") as f:\n",
    "    projects = json.load(f)\n",
    "\n",
    "# choose project\n",
    "project = projects[\"dev\"]\n",
    "env_path = Path(ENV_DIR / f'{project[\"env\"]}_roadly.env')\n",
    "\n",
    "_ = load_dotenv(env_path)  # read local .env file\n",
    "google_app_creds = os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
    "roadly_cookie = os.getenv(\"ROADLY_COOKIE\")\n",
    "print(f\"Initial configuration has finished:\\nProject: {project}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_app_creds = os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
    "browser = GSBrowser(project=project[\"project\"], credentials=google_app_creds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "May be used for checking object existence in a bucket.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "assert all(\n",
    "    [\n",
    "        browser.is_present(\"roadly-ds-datasets-coldline/testing\"),\n",
    "        browser.is_present(\"gs://roadly-ds-datasets-coldline/testing\"),\n",
    "        browser.is_present(\n",
    "            \"https://storage.googleapis.com/roadly-ds-datasets-coldline/testing\"\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "browser.is_present(\"roadly-ds-datasets-coldline/testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/apoyezzhayev/ds_contrib/blob/main/ds_contrib/tools/io/gscloud.py#L375){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### GSBrowser.list\n",
       "\n",
       ">      GSBrowser.list\n",
       ">                      (context:__main__.GSBrowserContextDTO|None|str|pathlib.Pa\n",
       ">                      th=None, fields:str=None, recursive:bool=False,\n",
       ">                      as_dir=None, max_results:int=None)\n",
       "\n",
       "List blobs as GSBrowserContextDTO files and folders in prefix directory\n",
       "\n",
       "analogous to `ls` in bash\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| context | GSBrowserContext | None | prefix directory, root of the hierarchy, if None then current context is used, by default None |\n",
       "| fields | str | None | fields to return, see https://googleapis.dev/python/storage/latest/blobs.html#google.cloud.storage.blob.Blob, by default None |\n",
       "| recursive | bool | False | if True then list blobs recursively, by default False, Warning: if True, then all blobs are listed and then filtered, may be slow |\n",
       "| as_dir | NoneType | None | if True then consider prefix as directory, during listing subfolders and files will be returned,<br>if False then consider prefix as file, if it is a directory, then return only this directory GSBrowserContextDTO,<br>if None then infer from the prefix (if it ends with `/`), by default None |\n",
       "| max_results | int | None | maximum number of results to return, if None then all results are returned, by default None |\n",
       "| **Returns** | **dict[str, list[GSBrowserContextDTO]]** |  | **dictionary with keys `files` and `folders` with lists of GSBrowserContextDTO files and folders respectively** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/apoyezzhayev/ds_contrib/blob/main/ds_contrib/tools/io/gscloud.py#L375){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### GSBrowser.list\n",
       "\n",
       ">      GSBrowser.list\n",
       ">                      (context:__main__.GSBrowserContextDTO|None|str|pathlib.Pa\n",
       ">                      th=None, fields:str=None, recursive:bool=False,\n",
       ">                      as_dir=None, max_results:int=None)\n",
       "\n",
       "List blobs as GSBrowserContextDTO files and folders in prefix directory\n",
       "\n",
       "analogous to `ls` in bash\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| context | GSBrowserContext | None | prefix directory, root of the hierarchy, if None then current context is used, by default None |\n",
       "| fields | str | None | fields to return, see https://googleapis.dev/python/storage/latest/blobs.html#google.cloud.storage.blob.Blob, by default None |\n",
       "| recursive | bool | False | if True then list blobs recursively, by default False, Warning: if True, then all blobs are listed and then filtered, may be slow |\n",
       "| as_dir | NoneType | None | if True then consider prefix as directory, during listing subfolders and files will be returned,<br>if False then consider prefix as file, if it is a directory, then return only this directory GSBrowserContextDTO,<br>if None then infer from the prefix (if it ends with `/`), by default None |\n",
       "| max_results | int | None | maximum number of results to return, if None then all results are returned, by default None |\n",
       "| **Returns** | **dict[str, list[GSBrowserContextDTO]]** |  | **dictionary with keys `files` and `folders` with lists of GSBrowserContextDTO files and folders respectively** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(GSBrowser.list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Navigation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main usage scenario: list all buckets, objects (files and folders) in a bucket\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Bucket: gitlab-runners-cache-904b>,\n",
       " <Bucket: roadly-dev-backups>,\n",
       " <Bucket: roadly-dev-cloudsql-exports>,\n",
       " <Bucket: roadly-dev-frontend-assets>,\n",
       " <Bucket: roadly-dev-metadata>,\n",
       " <Bucket: roadly-dev-persistent>,\n",
       " <Bucket: roadly-dev-pipelines>,\n",
       " <Bucket: roadly-dev-rda>,\n",
       " <Bucket: roadly-dev-standard-backups>,\n",
       " <Bucket: roadly-dev-standard-frontend-assets>,\n",
       " <Bucket: roadly-dev-standard-metadata>,\n",
       " <Bucket: roadly-dev-standard-metadata-backup>,\n",
       " <Bucket: roadly-dev-standard-persistent>,\n",
       " <Bucket: roadly-dev-standard-pipelines>,\n",
       " <Bucket: roadly-dev-standard-rda>,\n",
       " <Bucket: roadly-dev-standard-videos>,\n",
       " <Bucket: roadly-dev-videos>,\n",
       " <Bucket: roadly-ds-datasets-coldline>,\n",
       " <Bucket: roadly-hdm-osrm-dev>,\n",
       " <Bucket: roadly-run-local-alex-rda>,\n",
       " <Bucket: roadly-runners-cache-bc18-dev>,\n",
       " <Bucket: roadly-test-s3>,\n",
       " <Bucket: tf-state-roadly-dev>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "browser.list_buckets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'files': [],\n",
       " 'folders': [GSBrowserContext:\n",
       "  \tbucket | roadly-ds-datasets-coldline\n",
       "  \tprefix | testing/\n",
       "  \tis_dir | True\n",
       "  \tback | None,\n",
       "  GSBrowserContext:\n",
       "  \tbucket | roadly-ds-datasets-coldline\n",
       "  \tprefix | testing/tmp/\n",
       "  \tis_dir | True\n",
       "  \tback | None]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "browser.list(\"roadly-ds-datasets-coldline/testing\", as_dir=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also may be used as a standard path utils as in file system, with `cd`, `cwd`, `list`, `back`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'files': [],\n",
       " 'folders': [GSBrowserContext:\n",
       "  \tbucket | roadly-ds-datasets-coldline\n",
       "  \tprefix | testing/\n",
       "  \tis_dir | True\n",
       "  \tback | None,\n",
       "  GSBrowserContext:\n",
       "  \tbucket | roadly-ds-datasets-coldline\n",
       "  \tprefix | testing/tmp/\n",
       "  \tis_dir | True\n",
       "  \tback | None]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "browser.cd(\"roadly-ds-datasets-coldline/testing\")\n",
    "browser.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'files': [],\n",
       " 'folders': [GSBrowserContext:\n",
       "  \tbucket | roadly-ds-datasets-coldline\n",
       "  \tprefix | catalogue/\n",
       "  \tis_dir | True\n",
       "  \tback | None,\n",
       "  GSBrowserContext:\n",
       "  \tbucket | roadly-ds-datasets-coldline\n",
       "  \tprefix | demo/\n",
       "  \tis_dir | True\n",
       "  \tback | None,\n",
       "  GSBrowserContext:\n",
       "  \tbucket | roadly-ds-datasets-coldline\n",
       "  \tprefix | testing/\n",
       "  \tis_dir | True\n",
       "  \tback | None]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "browser.cd(\"..\")\n",
    "browser.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'roadly-ds-datasets-coldline/'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "browser.cwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IO: download/upload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/apoyezzhayev/ds_contrib/blob/main/ds_contrib/tools/io/gscloud.py#L566){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### GSBrowser.download_files\n",
       "\n",
       ">      GSBrowser.download_files (contexts:Union[Iterable[__main__.GSBrowserConte\n",
       ">                                xtDTO|None|str|pathlib.Path],__main__.GSBrowser\n",
       ">                                ContextDTO,NoneType,str,pathlib.Path],\n",
       ">                                local_folder_path:str|os.PathLike|None=None,\n",
       ">                                remote_root:str|os.PathLike|None=None, existing\n",
       ">                                _handling:Literal['skip','overwrite','raise']='\n",
       ">                                skip')\n",
       "\n",
       "Analogue of `download_file` for multiple files use it for convenience\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| contexts | Iterifiable[GSBrowserContext] |  | contexts to download from, may be a single context or a list of contexts |\n",
       "| local_folder_path | PathLike | None | local folder path to download blobs to, if None, then use default path which corresponds to {download_dir}/{prefix}, by default None |\n",
       "| remote_root | PathLike | None | remote root path, if None, then shared root of all remote paths is used, by default None |\n",
       "| existing_handling | Literal['skip', 'overwrite', 'raise'] | skip | how to handle existing files:<br>    - &#39;skip&#39; - skip existing files<br>    - &#39;overwrite&#39; - overwrite existing files<br>    - &#39;raise&#39; - raise error if file already exists, by default &#39;skip&#39; |\n",
       "| **Returns** | **None** |  |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/apoyezzhayev/ds_contrib/blob/main/ds_contrib/tools/io/gscloud.py#L566){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### GSBrowser.download_files\n",
       "\n",
       ">      GSBrowser.download_files (contexts:Union[Iterable[__main__.GSBrowserConte\n",
       ">                                xtDTO|None|str|pathlib.Path],__main__.GSBrowser\n",
       ">                                ContextDTO,NoneType,str,pathlib.Path],\n",
       ">                                local_folder_path:str|os.PathLike|None=None,\n",
       ">                                remote_root:str|os.PathLike|None=None, existing\n",
       ">                                _handling:Literal['skip','overwrite','raise']='\n",
       ">                                skip')\n",
       "\n",
       "Analogue of `download_file` for multiple files use it for convenience\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| contexts | Iterifiable[GSBrowserContext] |  | contexts to download from, may be a single context or a list of contexts |\n",
       "| local_folder_path | PathLike | None | local folder path to download blobs to, if None, then use default path which corresponds to {download_dir}/{prefix}, by default None |\n",
       "| remote_root | PathLike | None | remote root path, if None, then shared root of all remote paths is used, by default None |\n",
       "| existing_handling | Literal['skip', 'overwrite', 'raise'] | skip | how to handle existing files:<br>    - &#39;skip&#39; - skip existing files<br>    - &#39;overwrite&#39; - overwrite existing files<br>    - &#39;raise&#39; - raise error if file already exists, by default &#39;skip&#39; |\n",
       "| **Returns** | **None** |  |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(GSBrowser.download_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arseniy/mambaforge/envs/rda_mvp/lib/python3.10/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Raises\n",
      "  else: warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/apoyezzhayev/ds_contrib/blob/main/ds_contrib/tools/io/gscloud.py#L634){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### GSBrowser.upload_files\n",
       "\n",
       ">      GSBrowser.upload_files (local_paths:Union[Iterable[str|os.PathLike|None],\n",
       ">                              str,os.PathLike,NoneType], gcs_destination_root:_\n",
       ">                              _main__.GSBrowserContextDTO|None|str|pathlib.Path\n",
       ">                              , duplicates_handling:Optional[Literal['overwrite\n",
       ">                              ','skip','error']]=None, recursive:bool=False,\n",
       ">                              local_shared_root:str|os.PathLike|None=None,\n",
       ">                              test_launch:bool=False)\n",
       "\n",
       "Upload multiple files to GCP\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| local_paths | Iterifiable[PathLike] |  | local paths to upload to GCP, may be iterable files and directories or a single file or directory |\n",
       "| gcs_destination_root | GSBrowserContext |  | root directory context (GSBrowserContext), this directory will be used as a root prefix for all uploaded files |\n",
       "| duplicates_handling | Literal['overwrite', 'skip', 'error'] \\| None | None | how to handle duplicates:<br>    - if None, then no checks for file existence are performed,<br>    - &#39;overwrite&#39; - overwrite existing files<br>    - &#39;skip&#39; - skip existing files<br>    - &#39;error&#39; - raise error if file already exists, by default None |\n",
       "| recursive | bool | False | if True, then upload folders recursively, otherwise only files of 1st level, by default False |\n",
       "| local_shared_root | PathLike | None | local paths are treated as relative to this root,<br>if None shared root of all files and directories in `local_paths` will be extracted automatically,<br>try to avoid this due to unpredictability, by default None |\n",
       "| test_launch | bool | False | if True, then do not upload files, only print what will be uploaded, by default False |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/apoyezzhayev/ds_contrib/blob/main/ds_contrib/tools/io/gscloud.py#L634){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### GSBrowser.upload_files\n",
       "\n",
       ">      GSBrowser.upload_files (local_paths:Union[Iterable[str|os.PathLike|None],\n",
       ">                              str,os.PathLike,NoneType], gcs_destination_root:_\n",
       ">                              _main__.GSBrowserContextDTO|None|str|pathlib.Path\n",
       ">                              , duplicates_handling:Optional[Literal['overwrite\n",
       ">                              ','skip','error']]=None, recursive:bool=False,\n",
       ">                              local_shared_root:str|os.PathLike|None=None,\n",
       ">                              test_launch:bool=False)\n",
       "\n",
       "Upload multiple files to GCP\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| local_paths | Iterifiable[PathLike] |  | local paths to upload to GCP, may be iterable files and directories or a single file or directory |\n",
       "| gcs_destination_root | GSBrowserContext |  | root directory context (GSBrowserContext), this directory will be used as a root prefix for all uploaded files |\n",
       "| duplicates_handling | Literal['overwrite', 'skip', 'error'] \\| None | None | how to handle duplicates:<br>    - if None, then no checks for file existence are performed,<br>    - &#39;overwrite&#39; - overwrite existing files<br>    - &#39;skip&#39; - skip existing files<br>    - &#39;error&#39; - raise error if file already exists, by default None |\n",
       "| recursive | bool | False | if True, then upload folders recursively, otherwise only files of 1st level, by default False |\n",
       "| local_shared_root | PathLike | None | local paths are treated as relative to this root,<br>if None shared root of all files and directories in `local_paths` will be extracted automatically,<br>try to avoid this due to unpredictability, by default None |\n",
       "| test_launch | bool | False | if True, then do not upload files, only print what will be uploaded, by default False |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(GSBrowser.upload_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload and download files from Google Cloud Storage buckets, still working slow due to the single process usage, will be improved in the future.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'roadly-ds-datasets-coldline/testing/tmp/'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "browser.cd(\"testing/tmp\")\n",
    "browser.cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2a322edf4c846fa8e2dc91b8bd019dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading files to GCP:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Uploading file from path: `/var/folders/nb/lz9dkqrs385bxpdkgm24ym1m0000gn/T/tmp06nu2muf` to URI: `GSBrowserContext:\n",
      "\tbucket | roadly-ds-datasets-coldline\n",
      "\tprefix | testing/tmp/tmp06nu2muf\n",
      "\tis_dir | False\n",
      "\tback | None\n",
      "`\n"
     ]
    }
   ],
   "source": [
    "# Create a temporary file\n",
    "with tempfile.NamedTemporaryFile(mode=\"w\", delete=True) as tmp_file:\n",
    "    local_path = tmp_file.name\n",
    "    browser.upload_files(\n",
    "        local_path, browser.cwd, local_shared_root=Path(local_path).parent\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'files': [GSBrowserContext:\n",
       "  \tbucket | roadly-ds-datasets-coldline\n",
       "  \tprefix | testing/tmp/tmp02f8xjw9\n",
       "  \tis_dir | False\n",
       "  \tback | None,\n",
       "  GSBrowserContext:\n",
       "  \tbucket | roadly-ds-datasets-coldline\n",
       "  \tprefix | testing/tmp/tmp06nu2muf\n",
       "  \tis_dir | False\n",
       "  \tback | None,\n",
       "  GSBrowserContext:\n",
       "  \tbucket | roadly-ds-datasets-coldline\n",
       "  \tprefix | testing/tmp/tmp18ivl4mk\n",
       "  \tis_dir | False\n",
       "  \tback | None,\n",
       "  GSBrowserContext:\n",
       "  \tbucket | roadly-ds-datasets-coldline\n",
       "  \tprefix | testing/tmp/tmp1nsyxqhu\n",
       "  \tis_dir | False\n",
       "  \tback | None,\n",
       "  GSBrowserContext:\n",
       "  \tbucket | roadly-ds-datasets-coldline\n",
       "  \tprefix | testing/tmp/tmp376t3blz\n",
       "  \tis_dir | False\n",
       "  \tback | None,\n",
       "  GSBrowserContext:\n",
       "  \tbucket | roadly-ds-datasets-coldline\n",
       "  \tprefix | testing/tmp/tmp6bpiaxtt\n",
       "  \tis_dir | False\n",
       "  \tback | None,\n",
       "  GSBrowserContext:\n",
       "  \tbucket | roadly-ds-datasets-coldline\n",
       "  \tprefix | testing/tmp/tmpedszgdr7\n",
       "  \tis_dir | False\n",
       "  \tback | None,\n",
       "  GSBrowserContext:\n",
       "  \tbucket | roadly-ds-datasets-coldline\n",
       "  \tprefix | testing/tmp/tmpexjbvys4\n",
       "  \tis_dir | False\n",
       "  \tback | None,\n",
       "  GSBrowserContext:\n",
       "  \tbucket | roadly-ds-datasets-coldline\n",
       "  \tprefix | testing/tmp/tmpghmidt2y\n",
       "  \tis_dir | False\n",
       "  \tback | None,\n",
       "  GSBrowserContext:\n",
       "  \tbucket | roadly-ds-datasets-coldline\n",
       "  \tprefix | testing/tmp/tmpk0n87a48\n",
       "  \tis_dir | False\n",
       "  \tback | None,\n",
       "  GSBrowserContext:\n",
       "  \tbucket | roadly-ds-datasets-coldline\n",
       "  \tprefix | testing/tmp/tmpkzj94pe7\n",
       "  \tis_dir | False\n",
       "  \tback | None,\n",
       "  GSBrowserContext:\n",
       "  \tbucket | roadly-ds-datasets-coldline\n",
       "  \tprefix | testing/tmp/tmpo7021l3g\n",
       "  \tis_dir | False\n",
       "  \tback | None,\n",
       "  GSBrowserContext:\n",
       "  \tbucket | roadly-ds-datasets-coldline\n",
       "  \tprefix | testing/tmp/tmpopc_3pak\n",
       "  \tis_dir | False\n",
       "  \tback | None,\n",
       "  GSBrowserContext:\n",
       "  \tbucket | roadly-ds-datasets-coldline\n",
       "  \tprefix | testing/tmp/tmpopysoe3y\n",
       "  \tis_dir | False\n",
       "  \tback | None,\n",
       "  GSBrowserContext:\n",
       "  \tbucket | roadly-ds-datasets-coldline\n",
       "  \tprefix | testing/tmp/tmppmaofcod\n",
       "  \tis_dir | False\n",
       "  \tback | None,\n",
       "  GSBrowserContext:\n",
       "  \tbucket | roadly-ds-datasets-coldline\n",
       "  \tprefix | testing/tmp/tmpt3mc5zh5\n",
       "  \tis_dir | False\n",
       "  \tback | None,\n",
       "  GSBrowserContext:\n",
       "  \tbucket | roadly-ds-datasets-coldline\n",
       "  \tprefix | testing/tmp/tmpx76lynmb\n",
       "  \tis_dir | False\n",
       "  \tback | None],\n",
       " 'folders': [GSBrowserContext:\n",
       "  \tbucket | roadly-ds-datasets-coldline\n",
       "  \tprefix | testing/tmp/\n",
       "  \tis_dir | True\n",
       "  \tback | None]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "browser.list(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ds_contrib.core.paths:Created temporary directory for downloads: `/Users/arseniy/Projects/dev/ds_contrib/nbs/tools/tmpvus8_ot2`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13668b91b92a4111aefac60243c68d88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading files from GCP:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Downloading file from URI: `testing/tmp/tmp06nu2muf` to path: `/Users/arseniy/Projects/dev/ds_contrib/nbs/tools/tmpvus8_ot2/tmp06nu2muf`\n"
     ]
    }
   ],
   "source": [
    "browser.download_files(f\"./{Path(local_path).name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{GSBrowserContext:\n",
       " \tbucket | roadly-ds-datasets-coldline\n",
       " \tprefix | testing/tmp/tmp06nu2muf\n",
       " \tis_dir | False\n",
       " \tback | None: Path('/Users/arseniy/Projects/dev/ds_contrib/nbs/tools/tmpvus8_ot2/tmp06nu2muf')}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "browser.get_local_paths_mapping(f\"./{Path(local_path).name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "002eaa7a9eb74e888854a856810338f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading files from GCP:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Downloading file from URI: `testing/tmp/tmp06nu2muf` to path: `/Users/arseniy/Projects/dev/ds_contrib/nbs/tools/tmpvus8_ot2/tmp/tmp/tmp/tmp06nu2muf`\n"
     ]
    }
   ],
   "source": [
    "browser.download_files(\n",
    "    f\"./{Path(local_path).name}\",\n",
    "    remote_root=\"/roadly-ds-datasets-coldline/testing\",\n",
    "    local_folder_path=browser.downloads_path / \"tmp/tmp\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ds_contrib.core.paths:Cleaning up temporary directory `/Users/arseniy/Projects/dev/ds_contrib/nbs/tools/tmpvus8_ot2`\n"
     ]
    }
   ],
   "source": [
    "browser.downloads_dir.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
